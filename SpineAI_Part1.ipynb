{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Cervical Spine MRI Analysis\n",
    "\n",
    "### This series of posts describes the creation of a deep learning model to interpret MRI scans of the cervical spine. The output of the deep learning model is then used to predict surgical outcome in a cohort of patients undergoing surgery for Degenerative Cervical Myelopathy\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Degenerative cervical myelopathy (DCM) is a chronic disease that causes progressive non-traumatic compression of the cervical spinal cord.  \n",
    "\n",
    "![image1](/image1.jpg)\n",
    "Figure 1 - A schematic representation of the constellation of anatomic changes that occur in DCM that lead to compression of the cervical spinal cord.\n",
    "\n",
    "As the compression of the spinal cord worsens DCM can cause neurologic deficits, impaired mobility, and significant impairment in quality of life. The CSM-International and CSM-North America clinical trials are the two largest clinical trials that studied patients with DCM. The two studies together included 757 patients with DCM. Every patient had an MRI scan of the cervical spine and then went on to have surgery. The patients were then assessed 6 months, 12 months, and 24 months following surgery. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Representation\n",
    "\n",
    "Each patient had a pre-operative MRI of the cervical spine that at a minimum included a T2-weighted and T1-weighted sequence with an axial and sagital series. Unfortunately the MRIs were stored in various formats. The majority were dicom files, but many were stored as a tiled series of jpegs or pngs. In addition some MRIs were missing or corrupted. We included only the MRIs that were stored as dicom files, which limited us to 320 patients. \n",
    "\n",
    "There are 4 basic ways of representing an MRI scan:\n",
    "* As a 3D point cloud.  \n",
    "* As a series of 2D images with one axis removed:\n",
    " * As a series of axial 2D images. This eliminates the Z-axis\n",
    " * As a series of sagittal 2D images. This eliminates the X-axis\n",
    " * As a series of coronal 2D images. This eliminates the Y-axis\n",
    "\n",
    "Each axial image is somewhat consistent in appearance along the length of the spinal cord â€“ it contains the spinal cord in the center, cerebro-spinal fluid (CSF) surrounding the spinal cord, ligaments and bone surrounding the CSF, and the muscle and soft tissue of the neck. In comparison, the saggital and coronal series show different pieces of anatomy in each image and each image in the series bears little resemblance to the other images. \n",
    "\n",
    "We chose to represent each MRI as a series of independent axial 2D images. This was advantageous because we could make use of existing deep learning models such as VGG16 or ResNet50. We chose to consider each axial slice independently of the other axial slices within the scan. We thought this would be a reasonable compromise. The downside of this approach is that any feature that manifests predominantly along the Z-axis would be lost. We extracted the T2-weighted axial sequence for each patient and stored them as a new set of dicom files. This was accomplished manually using OsiriX Lite. \n",
    "\n",
    "Table 1 - Summary of MRI parameters extracted from the T2-weighted axial dicom files across the study population. \n",
    "\n",
    "| Parameter       | Range          | Median    |\n",
    "|-----------------|----------------|-----------|\n",
    "| Slice Thickness | 2.5 - 6mm      | 4mm       |\n",
    "| Image width     | 256-512 vx     | 512 vx    |\n",
    "| Image height    | 256-512 vx     | 512 vx    |\n",
    "| Series Length   | 16 - 83 images | 62 images |\n",
    "\n",
    "![image3](/image3.jpg)\n",
    "Figure 2 - An example series of T2-weighted axial images from a single patient. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Labelling\n",
    "\n",
    "There are a number of pathalogic changes that can be identified in an MRI scan of a patient with DCM. The full range of imaging findings are summarized in this 2016 article from Neurosurgical Focus. (https://www.ncbi.nlm.nih.gov/pubmed/27246488) \n",
    "\n",
    "To summarize, the structural changes related to DCM that can be detected on MRI include:\n",
    "* Spinal cord compression\n",
    "* Cervical Stenosis\n",
    "* Cord signal change\n",
    "* Ligamentous Pathology\n",
    "* Spondylolysthesis\n",
    "* Sagittal Alignment \n",
    "\n",
    "We chose to focus our deep learning model on detecting spinal cord compression for the following reasons:\n",
    "* Spinal cord compression is highly sensive for myelopathy. The following 2010 study of 103 patients (https://www.ncbi.nlm.nih.gov/pubmed/20150835) found that spinal cord compression was 100% sensitive and 79.6% specific for clinical myelopathy. \n",
    "* Spinal cord compression can be reliably graded on T2-weighted axial images using a number of grading systems. The inter-rater reliability of these grading systems is greater than 80% and in some studies was over 95%. (https://www.ncbi.nlm.nih.gov/pubmed/27246488)\n",
    "* Even though spinal cord compression is not 100% specific for clinical myelopathy the presence of spinal cord compression is a concerning finding that warrents continued follow up. \n",
    "\n",
    "For these reasons we believed that a deep learning model capable of reliably detecting spinal cord compression would serve as a useful screening tool for detecting patients that had symptoms of clinical myelopathy or were at risk of developing clinical myelopathy. \n",
    "\n",
    "To standardize the data labelling we used the qualitative criteria outlined in this 2010 study. https://www.ncbi.nlm.nih.gov/pubmed/20150835. Importantly we did not differentiate between Partial spinal cord compression and circumfrential spinal cord compression. Instead we defined spinal cord compression as any indentation on the spinal cord parenchyma which changed the contour of the spinal cord perimeter. Labelers assessed each T2-weighted axial slice and assigned a label of:\n",
    "* 1: evidence of partial or circumfrential spinal cord compression or \n",
    "* 0: no spinal cord compression. \n",
    "\n",
    "![image4](/image4.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image labelling was completed using the dicomlabeler.py script which can also be found in the main repository. This script makes use of the pydicom package. This script expects images to be stored in the following file structure:\n",
    "```\n",
    " Root_Directory\n",
    " |\n",
    " +-- dicomlabeler.py\n",
    " |    \n",
    " +-- Patient1\n",
    " |  |  \n",
    " |  +-- ax_t2\n",
    " |      |\n",
    " |      +-- DicomImage1.dcm\n",
    " |      +-- DicomImage2.dcm\n",
    " |      +-- DicomImage3.dcm\n",
    " |      ...\n",
    " |      +-- DicomImage62.dcm\n",
    " |    \n",
    " +-- Patient2\n",
    " |  |  \n",
    " |  +-- ax_t2\n",
    " |      |\n",
    " |      +-- DicomImage1.dcm\n",
    " |      +-- DicomImage2.dcm\n",
    " |      +-- DicomImage3.dcm\n",
    " |      ...\n",
    " |      +-- DicomImage62.dcm\n",
    " |    \n",
    " +-- etc.\n",
    "```\n",
    "The script outputs a file called compression_label.csv into the patient directory containing the labels. \n",
    "\n",
    "```python\n",
    "import os\n",
    "from os.path import join, getsize, dirname\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import csv\n",
    "import pydicom\n",
    "from pydicom.filereader import read_dicomdir\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from glob import glob\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import scipy.ndimage\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.tools import FigureFactory as FF\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "\n",
    "#Define list of patient ids\n",
    "patient_id = []\n",
    "#Define lists for filepaths\n",
    "ax_t2_filepath = []\n",
    "#Define the root directory\n",
    "rootDir = os.path.join(os.path.dirname(os.path.realpath(__file__)),'images')\n",
    "#Fill list of patient ids\n",
    "patient_id = os.listdir(rootDir)\n",
    "print patient_id\n",
    "#Current patient id\n",
    "ident = int(raw_input('Enter Reference:'))\n",
    "print patient_id[ident]\n",
    "\n",
    "#Function, take patient id, output list of file paths for ax t2 dicoms\n",
    "def paths_ax_t2(patient_id):\n",
    "\tsubDir = os.path.join(rootDir,patient_id,'ax_t2')\n",
    "\tfor root, dirs, files in os.walk(subDir):\n",
    "\t\tfor fname in files:\n",
    "\t\t\tif fname.endswith('.dcm'):\n",
    "\t\t\t\timg_path = os.path.join(root,fname)\n",
    "\t\t\t\tax_t2_filepath.append(img_path)\n",
    "\treturn ax_t2_filepath\n",
    "\n",
    "t2_filepath = paths_ax_t2(patient_id[ident])\n",
    "print(len(t2_filepath))\n",
    "\n",
    "#Get ref file\n",
    "RefDs = pydicom.read_file(t2_filepath[0])\n",
    "#Load dimensions of the dicom sequence\n",
    "ConstPixelDims = (int(RefDs.Rows), int(RefDs.Columns), len(t2_filepath))\n",
    "\n",
    "# Make empty array based on extracted dimensions\n",
    "ArrayDicom = numpy.zeros(ConstPixelDims, dtype=RefDs.pixel_array.dtype)\n",
    "\n",
    "# loop through all the DICOM files\n",
    "for filenameDCM in t2_filepath:\n",
    "    # read the file\n",
    "    ds = pydicom.read_file(filenameDCM)\n",
    "    # store the raw image data\n",
    "    ArrayDicom[:, :, t2_filepath.index(filenameDCM)] = ds.pixel_array \n",
    "    \n",
    "plt.ion()\n",
    "category = []\n",
    "csvfile = os.path.join(rootDir,patient_id[ident],'compression_label.csv')\n",
    "for i in range(len(t2_filepath)):\n",
    "\tplt.imshow(ArrayDicom[:, :, i])\n",
    "\tplt.show()\n",
    "\tplt.pause(0.001)\n",
    "\tcategory.append(raw_input('compression?: '))\n",
    "\tprint(\"Remaining: %d\" % (len(t2_filepath)-i))\n",
    "\n",
    "\n",
    "with open(csvfile, \"w\") as output:\n",
    "\twriter = csv.writer(output, lineterminator='\\n')\n",
    "\tfor val in category:\n",
    "\t\twriter.writerow([val])\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of Labelling\n",
    "\n",
    "Two labelers independantly labelled 110 patients, corresponding to 6093 individual axial images. The remaining 270 images were not labelled at this stage and were kept for model testing. \n",
    "\n",
    "\n",
    "|              *           | Images Labelled Compressed | Images Labelled Not-Compressed |\n",
    "| ------------------------------------ |---------------------------- |-------------------------------- |\n",
    "| Labeler 1                         | 1423 / 6093 (23.4%)        | 4670 / 6093 (76.6%)            |\n",
    "| Labeeler 2                         | 1253 / 6093 (20.6%)        | 4840 / 6093 (79.4%)            |\n",
    "| Percent agreement between labelers | 88.1%                      | 96.4%                          |\n",
    "\n",
    "As you can see the two labellers had excellent agreement (96.4%) on images that were not compressed. The agreement was still good (88.1%) on compressed images. We examined the images where there was disagreement between the labellers and we found that these images tended to be ones with minimal partial compression. \n",
    "\n",
    "We next wrote the dicomconverter.py script. This script took as in input the T2-weighted axial series of images and the .csv file containing the labels assigned by the two labellers. It output a series of uncompressed .jpeg images with the label in the filename\n",
    "\n",
    "compression_label.index.jpeg\n",
    "\n",
    "ex)\n",
    "* notcompressed.1.jpeg (notcompressed indicated an image that was labelled notcompressed by both labelers)\n",
    "* notcompressed.2.jpeg\n",
    "* notcompressed.3.jpeg\n",
    "* compressed.4.jpeg (compresed indicated an image that was labelled as compressed by both labelers)\n",
    "* pcompressed.5.jpeg (pcompressed indicated an image with disagreement between the labelers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the next post I will go over how we designed and trained a deep learning model to classify these images. \n",
    "\n",
    "#### Zamir Merali"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
